# VLM Provider Options:
# - custom: Any OpenAI-compatible endpoint
# - ui_tars_1_0: Hugging Face for UI-TARS-1.0
# - ui_tars_1_5: Hugging Face for UI-TARS-1.5
# - doubao_1_5: VolcEngine Ark for Doubao-1.5-UI-TARS
# - doubao_1_5_vl: VolcEngine Ark for Doubao-1.5-thinking-vision-pro
VLM_PROVIDER=custom
VLM_BASE_URL=http://localhost:3000/v1
VLM_API_KEY=your-api-key
VLM_MODEL_NAME=your-model-name
# Set to 'true' to use OpenAI Response API instead of Chat Completions API
# Only enable if your model/proxy supports it
VLM_USE_RESPONSES_API=false
# Enable thinking mode for compatible models (shows reasoning process)
VLM_ENABLE_THINKING=false
# Maximum number of screenshots to include in conversation history (default: 5, range: 1-20)
VLM_MAX_IMAGE_LENGTH=5
